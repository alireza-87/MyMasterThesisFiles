\documentclass{masterthesis}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref} % links
\usepackage{graphicx}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

% macros
\newcommand*\sizet{SIZE\_T}
\newcommand*\libc{glibc}
\newcommand*\previnuse{PREV_INUSE}
\newcommand*\tch{tcache}
\newcommand*\fb{fast bins}
\newcommand*\ub{unsorted bins}

\begin{document}

\title{A survey of heap-exploitation techniques}

\author{Alireza Karimi}

\advisor{Giovanni Lagorio}

\examiner{Alessandro Armando}

\maketitle

\tableofcontents

\chapter{Introduction}

\chapter{Introduction to \libc{} Heap}

\section{Heap}

An application has different types of memory space, two must important are Heap and Stack. Usually, the stack is used to store local variables, also, It may use to pass the function's parameters. Unlike stack, Heap is a portion of memory which use by applications to dynamically allocate memory during run time. This means an application can request memory and freed memory during execution. The data stored in the heap are accessible by all thread, so, It's important to handle it properly. There is some other different between stack and heap too :
\begin{itemize}
	\item Heap memory can become fragment, but, Stack memory won't
	\item Heap can access to variable globally, but, the stack can access to a local variable only
	\item Heap memory allocation perform by developers, but, stack allocation perform by compilers
	\item Developer have to free heap's memory when they don't need it anymore, but , you wont have to handle stack
\end{itemize}
Each of mentioned memory spaces has advantages and disadvantages, as the result, which one to use depends on the circumstances. If you need to handle data in LIFO format then the stack is the better choice. As we mentioned, The input parameters of a function may send by stack, in this way compiler doesn't have to free up memory after return from the function because they remove automatically. Also, Stack memory space is a better solution for local variable access.

Every platform has a way to interact with heap memory, there are lots of allocators like iOS allocator, Free- BSD allocator, and Linux allocator. Our work specifically on \libc{} memory allocator which drives from ptmalloc heap implementations, which is itself derived from dlmalloc, so, at first we want to discuss \libc{} allocations algorithms and Methods. Consider the following code as an allocation sample : 

\begin{lstlisting}[language=c]
typedef struct 
{
    int field1;
    char* field2;
} SomeStruct;
 
int main()
{
    SomeStruct* myObject = (SomeStruct*)malloc(sizeof(SomeStruct));
    if(myObject != NULL)
    {
        myObject->field1 = 1234;
        myObject->field2 = 'Hello World!';
        do_stuff(myObject);
	free(myObject);
    }
    return 0;
}

\end{lstlisting}

The above code is a sample of how the c programming language might allocate and free memory on the heap. \libc{} has other functions to allocate and free memory too which we discuss future. In the following sections, we discuss how \libc{} manages heap memory space. 

\section{Chunk}

Allocation and free are not the only job of the heap manager. The Heap manager needs some mechanism to keep track of the previous allocation and free space. Moreover, the Heap manager needs to align memory in 8 bytes for a 32bit system, and 16Byte in a 64bit system. To achieve this, the heap manager needs to store some metadata.

This allocation metadata and padding store alongside the allocated memory by malloc which returns to the user. For this reason, the Heap manager uses a concept called ‘Chunk’, each chunk usually bigger than request memory allocation because of metadata and alignment. When the user sends a request for memory allocation, the heap manager finds a chunk which big enough for user data and metadata, then, returns a pointer to the User's data section of the chunk. the below code shows the chunk data structure :

\begin{lstlisting}[language=c]
struct malloc_chunk {
  INTERNAL_SIZE_T      mchunk_prev_size; 
  INTERNAL_SIZE_T      mchunk_size;
  struct malloc_chunk* fd; 
  struct malloc_chunk* bk;
  /* Only used for large blocks: pointer to next larger size.  */
  struct malloc_chunk* fd_nextsize;
  struct malloc_chunk* bk_nextsize;
};

typedef struct malloc_chunk* mchunkptr;
\end{lstlisting}

An allocated chunk data structure is different than a free chunk. An allocated chunk just has the size field's, however, a freed chunk has two pointers to find the next free chunk, also, Because of metadata and alignment, the final size of a chunk is different than requested. Consider the following code which allocates 3 chunks of 8 bytes and free them after :

\begin{lstlisting}[language=c]
int main()
{
	int *a = malloc(8);
	int *b = malloc(8);
	int *c = malloc(8);
	free(a);
	free(b);
	free(c);
}
\end{lstlisting}

Take a look at heap structure after allocation : 

\begin{lstlisting}[language=c]
Allocated chunk
Addr: 0x555555559290
Size: 0x21

Allocated chunk
Addr: 0x5555555592b0
Size: 0x21

Allocated chunk
Addr: 0x5555555592d0
Size: 0x21

Top chunk 
Addr: 0x5555555592f0
Size: 0x20d11
\end{lstlisting}

As you can see, after three allocations the heap has 4 chunks. The first three are requested by a user, the final chunk with a big size is the top chunk. The top chunk is the remaining free space in the current heap. now look at returned address by \libc{} :

\begin{lstlisting}[language=c]
pwndbg> p a
$3 = (int *) 0x5555555592a0
pwndbg> p b
$4 = (int *) 0x5555555592c0
pwndbg> p c
$5 = (int *) 0x5555555592e0
\end{lstlisting}
The returned address by \libc{} is not the address of chunk, but, the address of the data section. if We minus these two numbers we will see 16 bytes different which use for metadata. If you look at the chunk data structure, there are two INTERNAL\_SIZE\_T is used to keep the size of the chunk. The \libc{} documentation said ' |INTERNAL\_SIZE\_T is the word-size used for internal bookkeeping of chunk sizes' . The default size is equal to \sizet{}. Now if we take a look at inside the memory : 
\begin{lstlisting}
0x555555559290:	0x00000000	0x00000000	0x00000021	0x00000000
0x5555555592a0:	0x00000000	0x00000000	0x00000000	0x00000000
0x5555555592b0:	0x00000000	0x00000000	0x00000021	0x00000000
0x5555555592c0:	0x00000000	0x00000000	0x00000000	0x00000000
0x5555555592d0:	0x00000000	0x00000000	0x00000021	0x00000000
0x5555555592e0:	0x00000000	0x00000000	0x00000000	0x00000000
0x5555555592f0:	0x00000000	0x00000000	0x00020d11	0x00000000
0x555555559300:	0x00000000	0x00000000	0x00000000	0x00000000
\end{lstlisting}
In the above allocation, we have 16 bytes of metadata plus 8 bytes of memory allocation which total allocation becomes 24 bytes, however, \libc{} must keep memory in 16-byte alignment, as the result, the final allocation is 32 byte. Take a look at the size field in an allocated chunk, we can see the size is not 32 but 33. The reason is 3 last bits of size parse differently:
\begin{enumerate}
	\item A (NON\_MAIN\_ARENA) : 0 when previous chunk is free
	\item M (IS\_MMAPPED) : The chunk is obtained through mmap
	\item P (PREV\_INUSE) 0 for chunks in the main arena
\end{enumerate}
Free chunks need more metadata to keep the pointer of the next and previous free chunks. To achieve this, \libc{} uses the data section of the chunk as a place to keep pointer metadata in the free chunk. Take look at heap after call free function :
\begin{lstlisting}[language=c]
Free chunk 
Addr: 0x555555559290
Size: 0x21
fd: 0x00

Free chunk
Addr: 0x5555555592b0
Size: 0x21
fd: 0x5555555592a0

Free chunk 
Addr: 0x5555555592d0
Size: 0x21
fd: 0x5555555592c0

Top chunk
Addr: 0x5555555592f0
Size: 0x20d11
\end{lstlisting}
Also take look at inside memory again ,You can see , \libc{} keep pointer information in chunk's data section .
\begin{lstlisting}
0x555555559290:	0x00000000	0x00000000	0x00000021	0x00000000
0x5555555592a0:	0x00000000	0x00000000	0x55559010	0x00005555
0x5555555592b0:	0x00000000	0x00000000	0x00000021	0x00000000
0x5555555592c0:	0x555592a0	0x00005555	0x55559010	0x00005555
0x5555555592d0:	0x00000000	0x00000000	0x00000021	0x00000000
0x5555555592e0:	0x555592c0	0x00005555	0x55559010	0x00005555
0x5555555592f0:	0x00000000	0x00000000	0x00020d11	0x00000000
0x555555559300:	0x00000000	0x00000000	0x00000000	0x00000000
\end{lstlisting}
 
\section{Memory Allocation}
 First, we discuss the Heap manager in a simple algorithm, then, we discuss each part in detail.The first question is, Whats happens when the user requests a memory allocation : 
\begin{enumerate}
	\item Heap manager cheek previously freed chunk, if there is a chunk which big enough, then, return it.
	\item If the Heap manager unable to find a previously freed chunk, then look at the top chunk, If there is available free space, then allocated a new chunk and return it.
	\item If there is not enough space in Heap anymore, then ask Kernel for new memory allocation to the end of the heap and allocate chunk from this new space.
	\item If all the above space failed then malloc returns NULL, which means, we can’t allocate new space.
\end{enumerate}

\subsection{Allocation from Freed Chunks}
As we mention, Previously freed chunks are the first place search by the heap manager. Heap manager track of Freed chunks via some linked list call ‘bins’. When a new allocation request arrives, the heap manager looks at bins to find a big enough chunk. If the chunk has the same size, then the heap manager will return it, otherwise, if the chunk is bigger than the request, then, the heap manager will split it. There are several different types of bins which we discuss later.

\subsection{Allocation from Top Chunk}
So what’s happen if there were no suitable previously free space? In this situation, the Heap manager checks the remaining space at the end of the heap, if there is enough space to create a chunk then allocate a new chunk from the top of the heap space. 

\subsection{Ask Kernel for more memory}
So, Let's check what happens yet. First, the heap manager search through previously free chunk. Assume we don't have any suitable free chunk, as the result, the heap manager will perform chunk creation in the top chunk, however, the request is bigger than this space. If there is not enough space at the end of the heap, the heap manager will ask Linux Kernel for more memory. Now we have to discuss another system called ‘brk’. When a program has been started, the heap manager calls ‘sbrk’ which used the 'brk' system call. This system call allocates more memory just after where the program gets load which is the end of the heap. 
After a while, this system call will break, Because, the newly allocated region at the end of the program space will collide with another thing in the process’s space. Once this situation happens heap manager will unable to allocate contiguous memory space, so, by calling mmap try to allocate non-contiguous memory space. 

\section{MMAP}
As we mentioned, the Heap manager uses MMAP for large memory allocation instead of sbrk. Chunks metadata contain a special flag for these reasons which indicate this chunk allocated off-heap via mmap. After the user releases the memory by free(), these chunks are UNMMAP. By default, the MMAP threshold is 128KB to 512KB for 32-bit and 32MB for the 64-bit  system.

\section{ARENA}
Concurrency is a challenge in multi-thread applications, so, Heap manager is not safe from this issue. There are many solutions to overcome this problem. In the early days' heap managers used a simple global lock before every heap operation to overcome this situation, however, this approach has a great cost. In multi-thread applications with heavy use of heap, this strategy leads to huge performance issues, because, heap needs to lock many times.

To improve the performance ptmalloc2 introduces a concept called ‘Arena’. In this approach different thread has their Arena, also, Each arena manages their chunks, as the result, threads can work at the same time on different Arena without altering each other data.

When the process creates a new thread, the heap manager finds an unused Arena up to the maximum allowed number which is (2* the number of CPU core) for 32-bit and (8* the number of CPU core) for 64-bit. So, what happens when we reach max number? Thread has to share Arena.

As we saw before, the main Areas create and grow by the sbrk system call, however, this is not true for the second heap. The second heap creates via mmap.

\section{Sub Heap}
As we mentioned subhead works like the main heap, however, they have some differences. The main heap is located right after where the program starts in memory, they grow with the ‘sbrk’ system call. Sub heap create by use of mmap, so, they are not located where the program starts contiguously, moreover, the Heap manager expands them by ‘protect.
How heap manager create and manage the sub heap? In the first step, the heap manager asks the kernel to reserve an area of memory for the subheap by malloc. Reserving does not allocate memory to subheap, it just tells the kernel, Don’t use this area. Mmap by flags required page as PROT\_NONE achieve this goal.
On the next step, when the main heap expands by ‘sbrk’, the heap manager allocates the previously reserved area to subheap by calling ‘protect. What mprotect do? It concerts PROT\_NONE to PROT\_READ, PROT\_WRITE . In this way, at least the kernel allocates real physical memory to each subheap, subheap expand in mmap area until It fills all mmap reserve area.

\section{free}
Whats happens when the user does not need allocated space anymore? Simply, calling heap can free up space. Now, the question is how free() works? First, it needs to calculate the chunk address from the user pointer. User has a pointer to the user data section of the chunk, but, free() needs the actual address of chunk, so, by subtracting the pointer address from metadata size we can find the chunk address. You may ask what happens if we send an invalid pointer? This may lead to memory corruption, as the result, the heap manager does some security check before free up space :

\begin{enumerate}
	\item Is chunk align? 
	\item Is chunk size valid?
	\item Is Chunk in the Arena address space?
	\item Is it already free?
\end{enumerate}

\section{Bins}
	Bin is a mechanism that the Heap manager used to manage and organize recently freed chunks, so, they can be reused during the next allocations. The simplest solution to keep track of freed space is to store them in a giant bin, although this could work It is not a good solution. Malloc is very wildly used, so, this approach leads to a performance problem.
To improve performance, the heap manager uses different types of bins. There is 5 different type of bins: small bin, large bin, \fb{}, unsorted bin, tcache. All of the mentioned bins exist in the same area of heap manager source code. This is a list with 127 items, the index 0 is unused. 
Now, We want to discuss how the heap manager recycles a chunk for a new allocation. First, let's consider a simple schema :
\begin{enumerate}
	\item If the M-bit in metadata is set, then this chunk is allocated off-heap, so, It should be unmmap.
	\item Otherwise, if the chunk right before this chunk is free, then they will be merge
	\item If the chunk right after this chunk is free, then they will be merge
	\item After the merge, if the larger chunk is located at the top of the heap, then it will be absorbed into the end of the heap instead of adding to bins
	\item Otherwise, the freed chunk will add to the corresponding bin
\end{enumerate}

\subsection{Small Bins}
There are 62 small bins, Each of them store the same size of the chunk, as the result, each list is sorted by default, also, store and retrieve chunk from small bins is fast. In 32-bit system it store chunk size below 512 byte , In 64-bit system it store chunk size below 1024 Byte . 

\subsection{Large Bins}
For chunks over 512 bytes ( 1024 byte 64-bit ), the Heap manager uses another strategy call Large Bins. There are 63 Large Bins. The main difference between small and large bins is large bins use a size range instead of a fixed size for every bin. Every bin in the large bins store chunk with a unique size range instead of fixed size in small bins, in a way, they don’t overlap with each other.
The other difference is large bins need to manually sort during the insertion of a chunk. As the result large bins are slower than small bins, however, Large bins used less than small bins in a real program, so, this is not a big problem.

\subsection{\ub{}}
Usually free() follow by an allocation of the same size in a real program. The heap manager introduced another optimization call \ub{}. In this optimization, the heap manager merges freed chunk with its neighbors and puts it inside a general bin call \ub{} instead of finding the corresponding bin. When a new allocation request arrives, the heap manager iterate over all item in \ub{} , compares the request to each item , If an item is big enough for request, the heap manager returns it, otherwise move an item to the corresponding bin.consider following malloc code from \libc{} 2.23 :
\begin{lstlisting}[language=c]
for (;; ){
      int iters = 0;
      while ((victim = unsorted_chunks (av)->bk) != unsorted_chunks (av)){
      }
}
\end{lstlisting}
As you can see malloc iterate over all items inside \ub{}. We can conclude , when heap manager try to find chunk in unsorted bins , all of unsorted bins chunks will move to corresponding bins too.

\subsection{\fb{}}
This is the second optimizations on heap manager. These bins keep recently freed small chunk in a list. As we mention \ub{} merge chunk before add to bins , but, chunk in \ub{} does not merge with neighbors, instead, \fb{} keeps them alive, so, If program sends the same size request, then heap manager can use this chunks.
The main difference between \fb{} and small bins is \fb{} do not merge chunks with neighbors. How \fb{} do that? The heap manager doesn’t free up this chunk by don’t set P-bit. Of course, this strategy has a downside too, the memory of the process becomes full or fragment after a while, to overcome this issue heap manager need to ‘flushing ‘ memory from time to time. There is not any periodic job to flushing \fb{}, instead, \libc{} uses another variant of free function call malloc\_consolidate(). 

\subsection{\tch{} bins Bins}
\tch{} is the last optimizations in the heap manager which added since \libc{-2.26}. Usually, a process has multiple threads, and a resource-like heap is shared between threats. A shared resource between threads can lead to a problem called ‘race condition’. As we mentioned before, a simple strategy to overcome race conditions is 'lock'. The lock gave temporary ownership of resources to one threat. When the job of the first threat finishes, then the second one can proceed. The lock has a great cost for heap managers which is frequently used by a program. As we talk before, the Heap manager overcomes this problem by using a secondary Arena for each threat until hits the threshold, moreover, it uses \tch{} per-threat to reduce the cost of the lock. \tch{} speeds up the allocation by having per-threat bins of a small chunk. When a threat sends an allocation request, the first \tch{} of that threat check for available chunk, If \tch{} have a big enough chunk, then threat use it and don’t need to wait for a heap lock. In the first sample you can see chunks was add to \tch{} after call free ,however , If we execute same code on \libc{-2.23} we have different result because it does not support \tch{}

\begin{lstlisting}
Free chunk (tcache) 
Addr: 0x555555559290
Size: 0x21
fd: 0x00

Free chunk (tcache) 
Addr: 0x5555555592b0
Size: 0x21
fd: 0x5555555592a0

Free chunk (tcache) 
Addr: 0x5555555592d0
Size: 0x21
fd: 0x5555555592c0
\end{lstlisting}

\section{malloc()}
Let's put all it together to find out how malloc works. When a new allocation request arrives, malloc will do the following procedure :
Lets consider \libc{-2.31}, In these particular version \tch{} is the first place . If \tch{} have a chunk with the same size, the heap manager will return it immediately. If the chunk is bigger than the request, \tch{} won't split it, instead, the heap manager will keep it for future requests. In this case, the Arena does not need to lock because the chunk returns from \tch{} immediately. Consider the following code :
\begin{lstlisting}[language=c]
 if (tc_idx < mp_.tcache_bins && tcache && tcache->counts[tc_idx] > 0){
      return tcache_get (tc_idx);
}
\end{lstlisting}

The above code is located at libc\_malloc function, It's responsible to check and returns a chunk from tcache before lock the arena and search for a chunk. If the \tch{} fail, In the next step two situations may happen. If we have a single thread application there is no need to lock at Arena because there is no concurrency, instead, in a multi\-thread application heap manager first get the corresponding Arena then lock it at the first. The following code is responsible to check the mentioned situation :
\begin{lstlisting}[language=c]
if (SINGLE_THREAD_P){
      victim = _int_malloc (&main_arena, bytes);
      return victim;
}
arena_get (ar_ptr, bytes);
victim = _int_malloc (ar_ptr, bytes);
\end{lstlisting}

Now we discuss the \_int\_malloc() function . This function gets the request size and Arena then tries to allocate a chunk and return it from bins or top chunk. Let's consider \tch{} fails in the previous step. The next place to check is the fast bins. Also, As we mention, each fast bin keeps just one size of the chunk, as the result, remove and add a chunk to the fast bin is fast.
\begin{lstlisting}[language=c]
if ((unsigned long) (nb) <= (unsigned long) (get_max_fast ()))
\end{lstlisting}
In this step, while the heap manager checks the fast bin for a suitable chunk, It fills \tch{} too, if found a same size chunk in the fast bin. It's a performance improvement, Usually, the following allocation has the same size too, so, the next allocation will find in the \tch{} without the needs to Arena lock.
\begin{lstlisting}[language=c]
size_t tc_idx = csize2tidx (nb);
if (tcache && tc_idx < mp_.tcache_bins)
\end{lstlisting}

In the following step, the heap manager checks the small bins If the request is in the range of small bins chunk size. Like fast bins, each small bins keep one chunk size, so, there is no search too.
\begin{lstlisting}[language=c]
if (in_smallbin_range (nb)){
      idx = smallbin_index (nb);
      bin = bin_at (av, idx);
      if ((victim = last (bin)) != bin)
\end{lstlisting}

Unlike fast bins, chunks in small bins use a double link list, so, when you remove one chunk you have to fix the fd and bk pointers for previous and next chunks. 

\begin{lstlisting}[language=c]

idx = smallbin_index (nb);
bin = bin_at (av, idx);
bck = victim->bk;
bin->bk = bck;
bck->fd = bin;
\end{lstlisting}

Small bin attacks usually abuse this part of code to write data in a location by manipulating the pointer's data. Like what happens in a fast bin, the Heap manager adds the same size chunk to tcache too. If the request was not in the range of small bins, heap manager free and merge fast bins chunk in the first place.
\begin{lstlisting}[language=c]
malloc_consolidate (av);
\end{lstlisting}

Now it's time to check unsorted bins chunks. As we mention, the heap manager examines all of the unsorted bins chunks to find a suitable chunk. If the chunk is exatly same size it will return by heap manage , if it is bigger than the requested size heap manager will split the chunk return a chunk to the user and put the remaining chunks to corresponding bins too and remove them from the unsorted bin.
\begin{lstlisting}[language=c]
for (;; )   
      int iters = 0;
      while ((victim = unsorted_chunks (av)->bk) != unsorted_chunks (av))
\end{lstlisting}
This add and remove chunks needs to alter the fd and bk pointer of chunks which some times abused by an attacker to write data in a location . this part of code have some security check to find if the chunk and heap corrupted or not by checking the pointers and chunk size :
\begin{lstlisting}[language=c]

          if (__glibc_unlikely (size <= 2 * SIZE_SZ)
              || __glibc_unlikely (size > av->system_mem))
            malloc_printerr ("malloc(): invalid size (unsorted)");
          if (__glibc_unlikely (chunksize_nomask (next) < 2 * SIZE_SZ)
              || __glibc_unlikely (chunksize_nomask (next) > av->system_mem))
            malloc_printerr ("malloc(): invalid next size (unsorted)");
          if (__glibc_unlikely ((prev_size (next) & ~(SIZE_BITS)) != size))
            malloc_printerr ("malloc(): mismatching next->prev_size (unsorted)");
          if (__glibc_unlikely (bck->fd != victim)
              || __glibc_unlikely (victim->fd != unsorted_chunks (av)))
            malloc_printerr ("malloc(): unsorted double linked list corrupted");
          if (__glibc_unlikely (prev_inuse (next)))
            malloc_printerr ("malloc(): invalid next->prev_inuse (unsorted)");
\end{lstlisting}

If all of above strategy fails, the heap manager tries to allocate chunk from free space at top chunk :
\begin{lstlisting}[language=c]
use_top:
victim = av->top;
      size = chunksize (victim);
      if (__glibc_unlikely (size > av->system_mem))
        malloc_printerr ("malloc(): corrupted top size");
\end{lstlisting}
You can see , this part start with security check to . In the case the request size is bigger than top chunk , heap manager will call sysmalloc as the last .
\begin{lstlisting}[language=c]
  void *p = sysmalloc (nb, av);
  \end{lstlisting}
This function check if the system support mmap allocation and requested size is inside the mmap threshold then it will allocate memory by using mmap. If its fail means there is no memory anymore , so malloc will return a null pointer .
\section{calloc()}
Calloc is another glib function used to allocate memory. Calloc and malloc have one important difference. unlike malloc, calloc does not use \tch{}. If you have free chunks in \tch{} then request a new memory by calloc, the heap manager won't use them instead create a new chunk from the top chunk. consider the following sample 
\begin{lstlisting}[language=c]

int *a = malloc(8);
int *b = malloc(8);
free(a);
free(b);
calloc(1,8);
calloc(1,8);
\end{lstlisting}
If take a look at the heap state after calloc, you can see heap manager create new chunks from the top chunk and tcache chunks remain.

\section{Alignment()}

As we mention, one of the heap manager's responsibilities is to keep memory in 16-byte alignment. In short form, the heap manager return aligned memory in the allocation phase, then, When a user calls free to request a chunk, the heap manager checks the alignment of memory for security reasons too. First, see the allocation part :
\begin{lstlisting}[language=c]

#define SIZE_SZ  (sizeof(INTERNAL_SIZE_T))
#define MALLOC_ALIGN_MASK (MALLOC_ALIGNMENT - 1)
#define MINSIZE  (unsigned long)(((MIN_CHUNK_SIZE+MALLOC_ALIGN_MASK) & ~MALLOC_ALIGN_MASK))
#define MALLOC_ALIGNMENT       (2 *SIZE_SZ)

#define request2size(req)
(((req) + SIZE_SZ + MALLOC_ALIGN_MASK < MINSIZE)  ? MINSIZE : ((req) + SIZE_SZ + MALLOC_ALIGN_MASK) & ~MALLOC_ALIGN_MASK)
\end{lstlisting}
Malloc call request2size macro. This macro checks the request size, then return MINSIZE of allocation or an aligned allocation size. As we mentioned before, the heap manager saves some metadata alongside the user data, as the result, every chunk needs more space than the user requested also the allocation size cant be smaller than the minimum size. Now if we check the free function :

\begin{lstlisting}[language=c]

#define aligned_OK(m)  (((unsigned long)(m) & MALLOC_ALIGN_MASK) == 0)
f (__glibc_unlikely (size < MINSIZE || !aligned_OK (size)))
    {
      errstr = "free(): invalid size";
      goto errout;
    }
\end{lstlisting}
The free function checks if the size is bigger than the minimum allocation size, also, the size must be aligned otherwise an error will raise which means memory is corrupted.
\section{malloc\_consolidate()}
As the \libc{} document said, It's a specialized version of the free function that tears down chunks held in the \fb{}. When a new allocation request has arrived, in some conditions the heap manager calls this method to tears down \fb{} chunks. 

To find when malloc\_consolidate() calls, we invest two different versions of \libc{}. the first one is 2.23 and the second one is 2.33 which is the latest \libc{} version. The first usage is the malloc function , Consider the following code :
\begin{lstlisting}[language=c]
 if (in_smallbin_range (nb)){
 	malloc_consolidate (av);
 }else{
	 malloc_consolidate (av);
 }
\end{lstlisting}
As we tell, small/large bins are one of the places which malloc search to find free chunk at the first phase. During this check, the heap manager performs flush to move \fb{} chunk too. If we check mentioned section in the latest \libc{} version, we will see small bin check does not contain malloc\_consolidate() anymore.
\begin{lstlisting}[language=c]
 if (in_smallbin_range (nb)){
 	 
 }else{
	 malloc_consolidate (av);
 }
\end{lstlisting}

The second usage is when the heap manager wants to use the top chunk in malloc. consider the following code in malloc :
\begin{lstlisting}[language=c]
use_top:
else if (have_fastchunks (av)){
          malloc_consolidate (av);
          }
\end{lstlisting}

The third usage is not in the malloc, instead, it's about free function. consider the following code from the free function :
\begin{lstlisting}[language=c]
if ((unsigned long)(size) >= FASTBIN_CONSOLIDATION_THRESHOLD) {
      if (have_fastchunks(av))
	malloc_consolidate(av);
	}
\end{lstlisting}

The rest usage located at inside malloc\_trim and malloc\_opt

\chapter{Heap Exploitation }

\chapter{Conclusion}

\bibliographystyle{alphaurl}
\bibliography{bib}

\end{document}

